### по списку доп. фич

* работа с экосистемой

  * Использование менеджера зависимостей
  
   ```
   из всех имеющихся решений для себя выбирал https://github.com/constabulary/gb
   возможно, из-за того, что чем-то похож на nuget\npm, так же достаточно удобно организовывать проект, 
   где все микросервисы в 1 месте, а-ля solution из .NET
   
   Изучал вопрос о прототипе модулей в go lang 1.10, но на практике не успел попробовать 
   ```

  * Использование сторонних библиотек и фреймворков
  
   ```
   для MVP было достаточно httprouter, а в целом подбор в рамках решаемой задачи по следующим критериям: 
   проект не заброшен; 
   стабильное api;
   есть более-менее актуальные бенчмарки; 
   "читабельная" кодовая база с которой можно разобраться и изменить при необходимости. 
   В остальных случаях лучше изучить возможность форкнуть или сделать своё решение.
   ```   
    
  
* оформление

  * README
  
  ```
  минимальный вариант, чтобы знать как запустить. Можно конечно сделать godoc, 
  но "в идеале" следует подключить swagger для описание API
  ```
  
  * гитхаб
  
  `no comments`
  
* Оптимизация

  * Оптимизация загрузки и отдачи файлов(в первую очередь используемой
    памяти)
    
    ```
    здесь бы в первую очередь стоит организовать корректное потоковое 
    чтение\запись с выделением буферов с размером, заданным через конфиг. 
    В остальном минимум аллокаций, блокировок и "тяжелых" операций, 
    возможно, реализация своей zero-copy логики на уровне TCP-соедениния, чтение из сокетов с использование netpoll
    ```
  
  * Gzip сжатие ответов
    
    ```
    Если рассматривать вместе с предыдущим пунктом, то лучше организовать как трансформацию потока данных читаемого файла.            
    На первичном этапе достаточно настроить сжатие ответов на балансировщике.
    ```
  
  * Поддержка gzip запросов
    
    ```
    аналогично предыдущему пункту, на первом этапе можно настроить на уровне балансировщика         
    ```
  
  * хранение в сжатом виде
    
    ```
    зависит от решаемой задачи и доступных ресурсов: 
    если запросов "не очень" много и у данных не как такого TTL, то есть хранить надо на постоянной основе,
    тогда необходимо подбирать оптимальный алгоритм сжатия для хранения.
    если ресурсов ЦПУ гораздо меньше, чем ресурсов на хранение, то возможно стоит обойтись без сжатия.
    Надо подбирать оптимальный баланс между нагрузкой на обработку данных и их чтение\запись.
    ```
    
  * работа с большими файлами
    
    ```
    по-моему этот пункт относится к оптимизации раздачи\загрузки файлов, 
    так же если клиентская часть позволяет - нужна поддержка Range-Request
    ```
  
  * конкурентный доступ
    
    ```
    в MVP добавлена "минимальная поддержка", но для production-решения необходимо как минимум перестроить кодовую базу,
    чтобы была поддержка конвеера обработки данных и пул потоков\горутин: ряд горутин вычитывает\записывает данные 
    и отдает в потоки htttp-запросов, которые ожидают выполнения операций + покачественне поработать с блокировками и стратегиями записи, например, реализовать какой-то вариант copy-on-write и т.п.,
    чтобы работа с данными была консистеной
    ```
  
  * отдача фрагмента файла
    
    ```
    no comments. необходимо поддержка range requests       
    ```
  
* безопасность

  * Ограничение директории, доступной для записи
    
    ```
    ...
    ```
  
  * Лимиты на размер загружаемых файлов
    
    ```
    не знаю, что добавить. Обычный middleware с чтением параметров из конфига
    ```
  
  * механизм авторизации
    
    ```
    зависит от остальной инфраструктуры сервисов, никакого rocket-science, хоть http auth, хоть jwt или sso
    ```
  
  * https
    
    ```
    на первом этапе достаточно терминирования ssl на уровне баласировщика
    ```
  
  * Ограничение кол-во запросов по аккаунту или IP
    
    ```
    как самый простой вариант, реализация middleware c хранением RPS в runtime в разрезе IP-адресов         
    ```
  
  * привязка к создателю и запрет на изменение для других клиентов
  * квоты с местом и лимитом
    
    ```
    на мой взгляд, в этом и предыдущем пункте, подойдет вариант реализации ABAC, 
    с каким-то внешним хранилищем и унифицированными ответами REST-сервисом
    ```
  
  * http заголовки в ответах для вызова со сторонней веб-страницы
    
    ```
    если клиент - это браузер, то CORS необходимы        
    ```

* окружение

  * запуск из встроенного сервера
    
    ```
    ...
    ```
  
  * docker
    
    ```
    сделал минимальный вариант docker-образа, 
    но произошло небольшое ЧП - в последней версии docker for win - не пробрасываются порты, не успел проверить в других окружениях     
    ```
  
* остальное

  * Content Type
    
    ```
    Использовал вариант определения по расширению файла (mime.TypeByExtension), 
    но можно было подключить http.DetectContentType для определения по первым байтам содержимого      
    ```
  
  * Отдельный документ с описанием архитектуры подобного API,
    работающего с высокой нагрузкой(больше 100 запросов в секунду,
    терабайты данных)
    
    ```
    оочень большой простор для решения задачи, который может включать в себя много вопросов и вариантов решения в зависимости от ситуации.
    Скорее всего необходимо подбирать оптимальный вариант в соответствии с "цена\качество\время реализации" и за "один присест" это не решить
    
    Как минимум, есть следующие нюансы для итоговой архитектуры:
    - оптимальный подбор железа
    конфиг серверов в зависимости от характера нагрузки: чтение\запись, характер частоты обращения к данным и т.п.
    от этого зависит объем RAM, ЦПУ, оптимальные уровни задержки чтения\записи на СХД
        
    - балансировка нагрузки 
    например, по geodns, чтобы направить пользователя на ближайшие сервера, 
    или на уровне хэширования user id, где за данные пользователя будет отвечать определенный пул серверов
    
    - стратегия репликации и бэкапов данных
    режим репликации
    сколько реплик держать, на уровне одного ДЦ или нескольких, задержка в репликации и т.д.
    частота снятия бэкапов
    
    - кеширование и инвалидация кэша:
    например, если доставка Video-on-demand, подойдет LRU-cache, раздача статики - LFU-cache;
    необходимые уровни кэширования: http cache, response cache, cache per user и т.д.
    
    - отказоустойчивость
     стратегия обработки исключительных ситуаций, например,
     при раздаче больших файлов необходима поддержка "дозагрузки" данных
     при записи хранение недогруженных данных в промежуточном варианте
     стратегия восстановления при сбоях
     
    - уровни хранения данных
    например, "hot data" - RAM храним данные, которые нужны "здесь и сейчас"
    актуальные данные - SSD для оптимальной задержки и выдачи данных
    архив - сохраняем файлы, которые пользователю часто не требуются
    
    - система мониторинга и оповещений
    необходимо видеть метрики: нагрузка по железку, задержка запросов на веб-серверах, 
    средний размер раздачи, актуальность репликации, попадания запросов в кэш, кол-во ошибок.  
    
    - доп. бизнес требования к приложению
    постобработка данных: генерацию превью, конвертирование в несколько разрешений
    выгрузка нескольких файлов в архиве
    поддержка повторных попыток чтения\записи данных
    
    ```